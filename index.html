<!DOCTYPE HTML>
<html lang="en">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

    <title>Linyi Jin</title>

    <meta name="author" content="Linyi Jin">
    <meta name="viewport" content="width=device-width, initial-scale=1">

    <link rel="stylesheet" type="text/css" href="stylesheet.css">
    <link rel="icon" href="images/favicon.ico">
  </head>

  <body>
    <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr style="padding:0px">
              <td style="padding:2.5%;width:63%;vertical-align:middle">
                <p class="name" style="text-align: center;">
                  Linyi Jin
                </p>
                <p>
                    I am a third-year Ph.D. student at <a href="https://umich.edu/">the University of Michigan</a>, advised by Prof. <a href="https://cs.nyu.edu/~fouhey/">David Fouhey</a>. I work on computer vision and machine learning.
                </p>
                <p>
                  My research is related to 3D scene understanding, camera calibration and robotics. 

                  I was previously a Master student in <a href="https://robotics.umich.edu/">Robotics</a>. Before that, I received my B.S.E. degrees in Computer Science at <a href="https://cse.engin.umich.edu/">UM</a> and Mechanical Engineering at <a href="https://www.sjtu.edu.cn/">Shanghai Jiao Tong University</a> through a dual degree program at <a href="http://umji.sjtu.edu.cn/"> UM-SJTU Joint Institute</a>.

                </p>
                <p>
                    <mark>I am looking for internship position in 2024. Please feel free to contact me if you think Iâ€™d be a good match!</mark>
                </p>
                <p style="text-align:center">
                  <a href="mailto:jinlinyi@umich.edu">Email</a> &nbsp;/&nbsp;
                  <a href="data/CV_Linyi.pdf">CV</a> &nbsp;/&nbsp;
                  <a href="https://scholar.google.com/citations?hl=en&user=0mSVyjwAAAAJ">Google Scholar</a> &nbsp;/&nbsp;
                  <a href="https://github.com/jinlinyi">Github</a>
                </p>
              </td>
              <td style="padding:2.5%;width:40%;max-width:40%">
                <a href="images/linyi.jpeg"><img style="width:100%;max-width:100%" alt="profile photo" src="images/linyi.jpeg" class="hoverZoomLink"></a>
              </td>
            </tr>
          </tbody></table>
          <hr>


          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <h2>News</h2>
              <p>
                - [2023/09] I will be a visiting student at <img src="images/NYU_Short_RGB_Color.png" class="image-inline" /> since David is moving there! <br>
                - [2023/06] We have released <img src="images/hf-logo.png" class="image-inline" /> <a href="https://huggingface.co/spaces/jinlinyi/PerspectiveFields">demo</a> for PerspectiveFields. Try it out on your camera calibration problem! <br>
                - [2023/03] Perspective Fields for Single Image Camera Calibration is selected as a highlight! <br>
                - [2023/02] Two papers are accepted at CVPR 2023! <br>
              </p>
            </td>
          </tr>
        </tbody></table>
        
        <hr>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <h2>Work Experience</h2>
            </td>
          </tr>
        </tbody>

        
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
                <td style="padding:20px;width:25%;vertical-align:middle">
                    <img src="images/adobe.png"  width="100" height="100" style="border-style: none">
                </td>
                <td width="75%" valign="middle">
                    <a href="https://research.adobe.com/">
                    <span class="papertitle">Adobe Research</span>
                    </a>
                    <br>
                    Computer Vision Research Intern
                    <br>
                    Summer, 2019
                    <br>
                    Host: <a href="https://jimmie33.github.io/">Jianming Zhang</a>
                    <br>
                </td>
            </tr>
        </tbody></table>

        <hr>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
              <tr>
              <td style="padding:20px;width:100%;vertical-align:middle">
                <h2>Publications</h2>
              </td>
            </tr>
          </tbody></table>

          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>


      <tr onmouseout="pers_stop()" onmouseover="pers_start()">
        <td style="padding:20px;width:25%;vertical-align:middle">
          <div class="one">
            <div class="two" id='pers_image'><video  width=100% height=100% muted autoplay loop>
            <source src="images/projects/persfields/perspectiveFields.mp4" type="video/mp4">
            Your browser does not support the video tag.
            </video></div>
            <img src='images/projects/persfields/perspectiveFields-static.png' width="160">
          </div>
          <script type="text/javascript">
            function pers_start() {
              document.getElementById('pers_image').style.opacity = "1";
            }

            function pers_stop() {
              document.getElementById('pers_image').style.opacity = "0";
            }
            pers_stop()
          </script>
        </td>
        <td width="75%" valign="middle">
            <a href="https://arxiv.org/abs/2212.03239">
            <span class="papertitle">Perspective Fields for Single Image Camera Calibration.</span>
            </a>
            <br>
            <strong>Linyi Jin</strong>, 
            <a href="https://jimmie33.github.io/">Jianming Zhang</a>, 
            <a href="https://yannickhold.com/">Yannick Hold-Geoffroy</a>,
            <a href="http://www.oliverwang.info/">Oliver Wang</a>,
            <a href="http://kmatzen.com/">Kevin Matzen</a>,
            <a href="https://www.linkedin.com/in/matthew-sticha-746325202">Matthew Sticha</a>,
            <a href="https://web.eecs.umich.edu/~fouhey/">David Fouhey</a>
            <br>
            <em>CVPR</em>, 2023 (<span style="color:#a00"><b>Highlight -- 2.5% accept rate</b></span>)
            <br>
            
            <a href="https://jinlinyi.github.io/PerspectiveFields/">project page</a>
            /
            <a href="https://huggingface.co/spaces/jinlinyi/PerspectiveFields">demo</a>
            /
            <a href="https://arxiv.org/abs/2212.03239">arXiv</a>
            /
            <a href="https://github.com/jinlinyi/PerspectiveFields">code</a>
            /
            <a href="https://jinlinyi.github.io/PerspectiveFields/resources/bibtex.txt">bibtex</a>

            <p></p>
            <p>
            A novel image space representation for camera perspectives, facilitating precise calibration in in-the-wild environments and cropped images.
            </p>
        </td>
      </tr>


        <tr onmouseout="d2drdf_stop()" onmouseover="d2drdf_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
                <div class="one">
                  <div class="two" id='d2drdf_image'><video  width=100% height=100% muted autoplay loop>
                  <source src="images/projects/d2drdf/d2drdf.mp4" type="video/mp4">
                  Your browser does not support the video tag.
                  </video></div>
                  <img src='images/projects/d2drdf/d2drdf-static.png' width="160">
                </div>
                <script type="text/javascript">
                  function d2drdf_start() {
                    document.getElementById('d2drdf_image').style.opacity = "1";
                  }
      
                  function d2drdf_stop() {
                    document.getElementById('d2drdf_image').style.opacity = "0";
                  }
                  d2drdf_stop()
                </script>
            </td>
            <td width="75%" valign="middle">
                <a href="https://arxiv.org/pdf/2306.08671">
                <span class="papertitle">Learning to Predict Scene-Level Implicit 3D from Posed RGBD Data.</span>
                </a>
                <br>
                <a href="https://nileshkulkarni.github.io/">Nilesh Kulkarni</a>, 
                <strong>Linyi Jin</strong>, 
                <a href="https://web.eecs.umich.edu/~justincj/">Justin Johnson</a>,
                <a href="https://web.eecs.umich.edu/~fouhey/">David Fouhey</a>
                <br>
                <em>CVPR</em>, 2023
                <br>
                
                <a href="https://nileshkulkarni.github.io/d2drdf/">project page</a>
                /
                <a href="https://arxiv.org/pdf/2306.08671">arXiv</a>
                /
                <a href="https://github.com/nileshkulkarni/d2drdf/">code</a>
                /
                <a href="https://scholar.googleusercontent.com/scholar.bib?q=info:EyWgCym0e54J:scholar.google.com/&output=citation&scisdr=ClHcl0eWENuMikBkgzY:AFWwaeYAAAAAZNFimzaUhwbnhmwMZjCYYsmeYzs&scisig=AFWwaeYAAAAAZNFim75mAQvYiKyzesRZrZGSW80&scisf=4&ct=citation&cd=-1&hl=en">bibtex</a>
                

                <p></p>
                <p>
                Learning 3D implicit function from a single input image. Unlike other methods, D2-DRDF does not depend on mesh supervision during training and can directly operate with raw RGB-D data obtained from scene captures.
                </p>
            </td>
        </tr>


        <tr onmouseout="planeformer_stop()" onmouseover="planeformer_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
                <div class="one">
                  <div class="two" id='planeformer_image'><video  width=100% height=100% muted autoplay loop>
                  <source src="images/projects/planeformers/planeformers.mp4" type="video/mp4">
                  Your browser does not support the video tag.
                  </video></div>
                  <img src='images/projects/planeformers/planeformers.jpeg' width="160">
                </div>
                <script type="text/javascript">
                  function planeformer_start() {
                    document.getElementById('planeformer_image').style.opacity = "1";
                  }
      
                  function planeformer_stop() {
                    document.getElementById('planeformer_image').style.opacity = "0";
                  }
                  planeformer_stop()
                </script>
              </td>
            <td width="75%" valign="middle">
                <a href="https://arxiv.org/pdf/2208.04307">
                <span class="papertitle">PlaneFormers: From Sparse View Planes to 3D Reconstruction.</span>
                </a>
                <br>
                <a href="https://www.linkedin.com/in/samiragarwala/">Samir Agarwala</a>, 
                <strong>Linyi Jin</strong>, 
                <a href="https://crockwell.github.io/">Chris Rockwell</a>, 
                <a href="https://web.eecs.umich.edu/~fouhey/">David Fouhey</a>
                <br>
                <em>ECCV</em>, 2022
                <br>
                
                <a href="https://samiragarwala.github.io/PlaneFormers/">project page</a>
                /
                <a href="https://arxiv.org/abs/2208.04307">arXiv</a>
                /
                <a href="https://github.com/samiragarwala/PlaneFormers">code</a>
                /
                <a href="https://web.eecs.umich.edu/~fouhey/2022/planeformer/agarwala22.bib">bibtex</a>

                <p></p>
                <p>
                We introduce a simpler approach that uses a transformer applied to 3D-aware plane tokens to perform 3D reasoning. This is substantially more effective than SparsePlanes.
                </p>
            </td>
        </tr>

        <tr onmouseout="videoarti_stop()" onmouseover="videoarti_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
                <div class="one">
                  <div class="two" id='videoarti_image'>
                    <img src='images/projects/videoarti/output.jpeg' width="160">
                  </div>
                  <img src='images/projects/videoarti/input.jpeg' width="160">
                </div>
                <script type="text/javascript">
                  function videoarti_start() {
                    document.getElementById('videoarti_image').style.opacity = "1";
                  }
      
                  function videoarti_stop() {
                    document.getElementById('videoarti_image').style.opacity = "0";
                  }
                  videoarti_stop()
                </script>
            </td>
            <td width="75%" valign="middle">
                <a href="https://arxiv.org/abs/2203.16531">
                <span class="papertitle">Understanding 3D Object Articulation in Internet Videos.</span>
                </a>
                <br>
                <a href="https://jasonqsy.github.io/">Shengyi Qian</a>, 
                <strong>Linyi Jin</strong>, 
                <a href="https://crockwell.github.io/">Chris Rockwell</a>, 
                <a href="https://chicychen.github.io/">Siyi Chen</a>, 
                <a href="https://web.eecs.umich.edu/~fouhey/">David Fouhey</a>
                <br>
                <em>CVPR</em>, 2022
                <br>
                
                <a href="https://jasonqsy.github.io/Articulation3D/">project page</a>
                /
                <a href="https://arxiv.org/abs/2203.16531">arXiv</a>
                /
                <a href="https://github.com/JasonQSY/Articulation3D">code</a>
                /
                <a href="https://web.eecs.umich.edu/~fouhey/2022/articulation/qian22.bib">bibtex</a>

                <p></p>
                <p>
                We propose to investigate detecting and characterizing the 3D planar articulation of objects from ordinary videos.
                </p>
            </td>
        </tr>

        <tr onmouseout="sparseplanes_stop()" onmouseover="sparseplanes_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
                <div class="one">
                    <div class="two" id='sparseplanes_image'><video  width=100% height=100% muted autoplay loop>
                        <source src="images/projects/sparseplanes/sparseplanes.mp4" type="video/mp4">
                        Your browser does not support the video tag.
                        </video></div>
                  <img src='images/projects/sparseplanes/sparseplanes-static.png' width="160">
                </div>
                <script type="text/javascript">
                  function sparseplanes_start() {
                    document.getElementById('sparseplanes_image').style.opacity = "1";
                  }
      
                  function sparseplanes_stop() {
                    document.getElementById('sparseplanes_image').style.opacity = "0";
                  }
                  sparseplanes_stop()
                </script>
            </td>
            <td width="75%" valign="middle">
                <a href="https://arxiv.org/abs/2103.14644">
                <span class="papertitle">SparsePlanes: Planar Surface Reconstruction from Sparse Views.</span>
                </a>
                <br>
                <strong>Linyi Jin</strong>, 
                <a href="https://jasonqsy.github.io/">Shengyi Qian</a>, 
                <a href="http://andrewowens.com/">Andrew Owens</a>,  
                <a href="https://web.eecs.umich.edu/~fouhey/">David Fouhey</a>
                <br>
                <em>ICCV</em>, 2021 (<span style="color:#a00"><b>Oral</b></span>)
                <br>
                
                <a href="https://jinlinyi.github.io/SparsePlanes/">project page</a>
                /
                <a href="https://arxiv.org/abs/2103.14644">arXiv</a>
                /
                <a href="https://github.com/jinlinyi/SparsePlanes">code</a>
                /
                <a href="http://fouheylab.eecs.umich.edu/~jinlinyi/2021/sparseplane.bib">bibtex</a>

                <p></p>
                <p>
                We learn to reconstruct scenes from sparse views with an unknown relationship. We take advantage of planar regions and their geometric properties to recover the scene layout.
                </p>
            </td>
        </tr>

        <tr onmouseout="associative3d_stop()" onmouseover="associative3d_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
                <div class="one">
                    <div class="two" id='associative3d_image'><video  width=100% height=100% muted autoplay loop>
                        <source src="images/projects/associative3d/associative3d.mp4" type="video/mp4">
                        Your browser does not support the video tag.
                        </video></div>
                  <img src='images/projects/associative3d/associative3d-static.png' width="160">
                </div>
                <script type="text/javascript">
                  function associative3d_start() {
                    document.getElementById('associative3d_image').style.opacity = "1";
                  }
      
                  function associative3d_stop() {
                    document.getElementById('associative3d_image').style.opacity = "0";
                  }
                  associative3d_stop()
                </script>
            </td>
            <td width="75%" valign="middle">
                <a href="https://arxiv.org/abs/2007.13727">
                <span class="papertitle">Associative3D: Volumetric Reconstruction from Sparse Views.</span>
                </a>
                <br>
                <a href="https://jasonqsy.github.io/">Shengyi Qian</a>*, 
                <strong>Linyi Jin</strong>*, 
                <a href="https://web.eecs.umich.edu/~fouhey/">David Fouhey</a>
                <br>
                <em>ECCV</em>, 2020
                <br>
                
                <a href="https://jasonqsy.github.io/Associative3D/">project page</a>
                /
                <a href="https://arxiv.org/abs/2007.13727">arXiv</a>
                /
                <a href="https://github.com/JasonQSY/Associative3D">code</a>
                /
                <a href="http://fouheylab.eecs.umich.edu/~jinlinyi/2020/associative3d.bib">bibtex</a>

                <p></p>
                <p>
                    We can build a voxel-based reconstruction of images from two views, even without access to the relative camera positions.        
                </p>
                <p>
                    Invited presentation at ECCV 2020 Workshop <a href="https://holistic-3d.github.io/eccv20/index.html">Holistic Scene Structures for 3D Vision</a>.   
                </p>
            </td>
        </tr>

        <tr onmouseout="mps_stop()" onmouseover="mps_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
                <div class="one">
                    <div class="two" id='mps_image'><video  width=100% height=100% muted autoplay loop>
                        <source src="images/projects/mps/mps.mp4" type="video/mp4">
                        Your browser does not support the video tag.
                        </video></div>
                  <img src='images/projects/mps/mps-static.png' width="160">
                </div>
                <script type="text/javascript">
                  function mps_start() {
                    document.getElementById('mps_image').style.opacity = "1";
                  }
      
                  function mps_stop() {
                    document.getElementById('mps_image').style.opacity = "0";
                  }
                  mps_stop()
                </script>
            </td>
            <td width="75%" valign="middle">
                <a href="https://arxiv.org/abs/1907.08770">
                <span class="papertitle">Inferring Occluded Geometry Improves Performance when Retrieving an Object from Dense Clutter.</span>
                </a>
                <br>
                <a href="http://www.prism.gatech.edu/~aprice6/#">Andrew Price</a>*, 
                <strong>Linyi Jin</strong>*, 
                <a href="http://web.eecs.umich.edu/~dmitryb/">Dmitry Berenson</a>
                <br>
                <em>ISRR</em>, 2019
                <br>
                
                <a href="deprecated/mps.html">project page</a>
                /
                <a href="https://arxiv.org/abs/1907.08770">arXiv</a>
                /
                <a href="http://fouheylab.eecs.umich.edu/~jinlinyi/2019/mps.bib">bibtex</a>

                <p></p>
                <p>
                    We augment a manipulation planner for cluttered environments with a shape completion network and a volumetric memory system, allowing the robot to reason about what may be contained in occluded areas.
                </p>
            </td>
        </tr>

        </tbody></table>

        <hr>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <h2>Teaching</h2>
            </td>
          </tr>
        </tbody>

        
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
                <td style="padding:20px;width:25%;vertical-align:middle">
                    <img src="images/442.jpeg"  width="160" height="160" style="border-style: none">
                </td>
                <td width="75%" valign="middle">
                    <a href="https://web.eecs.umich.edu/~fouhey/teaching/EECS442_W19/">
                    <span class="papertitle">EECS 442 Computer Vision (Winter '19)</span>
                    </a>
                    <br>
                    IA with <a href="https://web.eecs.umich.edu/~fouhey/">David Fouhey</a>.
                    <br>
                </td>
            </tr>
        </tbody></table>

        <hr>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
              <td style="padding:0px">
                <br>
                <p style="text-align:right;font-size:small;">
                  This website uses template from <a href="https://jonbarron.info/">Jon Barron</a>.
                </p>
              </td>
            </tr>
          </tbody></table>
        </td>
      </tr>
    </table>
  </body>
</html>